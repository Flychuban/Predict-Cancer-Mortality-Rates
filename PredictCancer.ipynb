{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1_HR8BS0O5oe2GEYLQsHE4I2WCQOnssFA",
      "authorship_tag": "ABX9TyMgWUV2zOW6/uGhLaMXN3xp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Flychuban/Predict-Cancer-Mortality-Rates/blob/main/PredictCancer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rT8-Pb6jz4NH"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "8-UJTeGA6E34"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/CancerMortalityRatesPredict/data/cancer_reg.csv\")"
      ],
      "metadata": {
        "id": "ru5qNuIQ0j3Z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_constant_columns(dataframe):\n",
        "    \"\"\"\n",
        "    This function takes in a dataframe and returns the columns that contain a single value.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pandas.DataFrame): The dataframe to be analyzed\n",
        "\n",
        "    Returns:\n",
        "    list: A list of columns that contain a single value\n",
        "    \"\"\"\n",
        "    constant_columns = []\n",
        "    for column in dataframe.columns:\n",
        "        # Get unique values in the column\n",
        "        unique_values = dataframe[column].unique()\n",
        "        # check if the column contains only one unique value\n",
        "        if len(unique_values) == 1:\n",
        "            constant_columns.append(column)\n",
        "    return constant_columns"
      ],
      "metadata": {
        "id": "PxO48mgy6tFG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_constant_columns(dataframe, columns_to_delete):\n",
        "    \"\"\"\n",
        "    This function takes in a dataframe and a list of columns to delete and deletes the columns that contain a single value.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pandas.DataFrame): The dataframe to be analyzed\n",
        "    columns_to_delete (list): A list of columns to delete\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: The dataframe with columns that contain a single value deleted\n",
        "    \"\"\"\n",
        "    # Delete the specified columns\n",
        "    dataframe = dataframe.drop(columns_to_delete, axis=1)\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "3WcAGT8v7ZVW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_columns_with_few_values(dataframe, threshold):\n",
        "    \"\"\"\n",
        "    This function takes in a dataframe and a threshold value as input and returns the columns that have less than the threshold number of unique values.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pandas.DataFrame): The dataframe to be analyzed\n",
        "    threshold (int): The minimum number of unique values required for a column\n",
        "\n",
        "    Returns:\n",
        "    list: A list of columns that have less than the threshold number of unique values\n",
        "    \"\"\"\n",
        "    few_values_columns = []\n",
        "    for column in dataframe.columns:\n",
        "        # Get the number of unique values in the column\n",
        "        unique_values_count = len(dataframe[column].unique())\n",
        "        # Check if the column has less than the threshold number of unique values\n",
        "        if unique_values_count < threshold:\n",
        "            few_values_columns.append(column)\n",
        "    return few_values_columns"
      ],
      "metadata": {
        "id": "xnepg3-i7qGc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_duplicate_rows(dataframe):\n",
        "    \"\"\"\n",
        "    This function takes in a dataframe as input and returns the rows that contain duplicate data.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pandas.DataFrame): The dataframe to be analyzed\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: The dataframe containing duplicate rows\n",
        "    \"\"\"\n",
        "    # Identify duplicate rows\n",
        "    duplicate_rows = dataframe[dataframe.duplicated()]\n",
        "    return duplicate_rows"
      ],
      "metadata": {
        "id": "1F-0aVLT8Uwk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def delete_duplicate_rows(dataframe):\n",
        "    \"\"\"\n",
        "    This function takes in a dataframe as input and deletes the rows that contain duplicate data.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pandas.DataFrame): The dataframe to be analyzed\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: The dataframe without duplicate rows\n",
        "    \"\"\"\n",
        "    # Drop duplicate rows\n",
        "    dataframe = dataframe.drop_duplicates(keep=\"first\")\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "pYALqDKI8Vg-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_and_fill(dataframe):\n",
        "    # Get the columns with more than 50% missing values\n",
        "    cols_to_drop = dataframe.columns[dataframe.isnull().mean() > 0.5]\n",
        "    # Drop the columns\n",
        "    dataframe = dataframe.drop(cols_to_drop, axis=1)\n",
        "    # Fill the remaining missing values with the mean of the column\n",
        "    dataframe = dataframe.fillna(dataframe.mean())\n",
        "    return dataframe"
      ],
      "metadata": {
        "id": "vuNeGEpW8oOV"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(dataframe, target_column):\n",
        "    \"\"\"\n",
        "    This function takes in a dataframe and a target column as input and splits the dataframe into a feature dataframe and a target dataframe.\n",
        "\n",
        "    Parameters:\n",
        "    dataframe (pandas.DataFrame): The dataframe to be analyzed\n",
        "    target_column (str): The name of the target column\n",
        "\n",
        "    Returns:\n",
        "    pandas.DataFrame: The dataframe containing the features\n",
        "    pandas.DataFrame: The dataframe containing the target column\n",
        "    \"\"\"\n",
        "    # Split the dataframe into a feature dataframe and a target dataframe\n",
        "    X = dataframe.drop(target_column, axis=1)\n",
        "    y = dataframe[target_column]\n",
        "    X_train, X_test, y_train, y_test = tts(X, y, test_size=0.2, random_state=0)\n",
        "    return (X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "rLhSBLcR9Dto"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bin_to_num(data):\n",
        "    binnedinc = []\n",
        "    for i in data[\"binnedinc\"]:\n",
        "        # remove the parentheses and brackets\n",
        "        i = i.strip(\"()[]\") \n",
        "        print(i)\n",
        "        # split the string into a list after splitting by comma\n",
        "        i = i.split(\",\")\n",
        "        print(i)\n",
        "        # convert the list to a tuple\n",
        "        i = tuple(i) \n",
        "        print(i)\n",
        "        # convert individual elements to float\n",
        "        i = tuple(map(float, i)) \n",
        "        print(i)\n",
        "        # convert the tuple to a list\n",
        "        i = list(i) \n",
        "        print(i)\n",
        "        # append the list to the binnedinc list\n",
        "        binnedinc.append(i)\n",
        "    data[\"binnedinc\"] = binnedinc\n",
        "\n",
        "    # make a new column lower and upper bound\n",
        "    data[\"lower_bound\"] = [i[0] for i in data[\"binnedinc\"]]  # lower bound\n",
        "    data[\"upper_bound\"] = [i[1] for i in data[\"binnedinc\"]]  # upper bound\n",
        "    # and also median point\n",
        "    data[\"median\"] = (data[\"lower_bound\"] + data[\"upper_bound\"]) / 2\n",
        "    # drop the binnedinc column\n",
        "    data.drop(\"binnedinc\", axis=1, inplace=True)\n",
        "    return data"
      ],
      "metadata": {
        "id": "b51gFdj19vWA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cat_to_col(data):\n",
        "    # make a new column by splitting the geography column\n",
        "    data[\"county\"] = [i.split(\",\")[0] for i in data[\"geography\"]]\n",
        "    data[\"state\"] = [i.split(\",\")[1] for i in data[\"geography\"]]\n",
        "    # drop the geography column\n",
        "    data.drop(\"geography\", axis=1, inplace=True)\n",
        "    return data"
      ],
      "metadata": {
        "id": "jA8_sOUo_nxQ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(X):\n",
        "    # select categorical columns\n",
        "    categorical_columns = X.select_dtypes(include=[\"object\"]).columns\n",
        "    # one hot encode categorical columns\n",
        "    one_hot_encoder = OneHotEncoder(sparse=False, handle_unknown=\"ignore\")\n",
        "    one_hot_encoded = one_hot_encoder.fit_transform(X[categorical_columns])\n",
        "    # convert the one hot encoded array to a dataframe\n",
        "    one_hot_encoded = pd.DataFrame(\n",
        "        one_hot_encoded, columns=one_hot_encoder.get_feature_names_out(categorical_columns)\n",
        "    )\n",
        "    # drop the categorical columns from the original dataframe\n",
        "    X = X.drop(categorical_columns, axis=1)\n",
        "    # concatenate the one hot encoded dataframe to the original dataframe\n",
        "    X = pd.concat([X, one_hot_encoded], axis=1)\n",
        "    return X"
      ],
      "metadata": {
        "id": "OpDYqxYQ__W4"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "constant_columns = find_constant_columns(df)\n",
        "print(f\"Columns that contain single value: {constant_columns}\")"
      ],
      "metadata": {
        "id": "uk_fZLVyAqAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1257d174-1360-4123-bda0-a3a056199c63"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns that contain single value: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_with_few_values = find_columns_with_few_values(df, 10)\n",
        "columns_with_few_values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo6kpt_72Uqf",
        "outputId": "f433a17a-f162-463e-bd16-a519cecfa039"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# df = bin_to_num(df)\n",
        "# df = cat_to_col(df)\n",
        "df = one_hot_encoding(df)\n",
        "df = drop_and_fill(df)\n",
        "print(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YzEbELzz279h",
        "outputId": "34229935-0459-418d-ddf2-d3d8638c4dd3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      avganncount  avgdeathsperyear  target_deathrate  incidencerate  \\\n",
            "0     1397.000000               469             164.9     489.800000   \n",
            "1      173.000000                70             161.3     411.600000   \n",
            "2      102.000000                50             174.7     349.700000   \n",
            "3      427.000000               202             194.8     430.400000   \n",
            "4       57.000000                26             144.4     350.100000   \n",
            "...           ...               ...               ...            ...   \n",
            "3042  1962.667684                15             149.6     453.549422   \n",
            "3043  1962.667684                43             150.1     453.549422   \n",
            "3044  1962.667684                46             153.9     453.549422   \n",
            "3045  1962.667684                52             175.0     453.549422   \n",
            "3046  1962.667684                48             213.6     453.549422   \n",
            "\n",
            "      medincome  popest2015  povertypercent  studypercap  medianage  \\\n",
            "0         61898      260131            11.2   499.748204       39.3   \n",
            "1         48127       43269            18.6    23.111234       33.0   \n",
            "2         49348       21026            14.6    47.560164       45.0   \n",
            "3         44243       75882            17.1   342.637253       42.8   \n",
            "4         49955       10321            12.5     0.000000       48.3   \n",
            "...         ...         ...             ...          ...        ...   \n",
            "3042      46961        6343            12.4     0.000000       44.2   \n",
            "3043      48609       37118            18.8   377.175494       30.4   \n",
            "3044      51144       34536            15.0  1968.959926       30.9   \n",
            "3045      50745       25609            13.3     0.000000       39.0   \n",
            "3046      41193       37030            13.9     0.000000       26.2   \n",
            "\n",
            "      medianagemale  ...  state_ South Dakota  state_ Tennessee  state_ Texas  \\\n",
            "0              36.9  ...                  0.0               0.0           0.0   \n",
            "1              32.2  ...                  0.0               0.0           0.0   \n",
            "2              44.0  ...                  0.0               0.0           0.0   \n",
            "3              42.2  ...                  0.0               0.0           0.0   \n",
            "4              47.8  ...                  0.0               0.0           0.0   \n",
            "...             ...  ...                  ...               ...           ...   \n",
            "3042           41.1  ...                  0.0               0.0           0.0   \n",
            "3043           29.3  ...                  0.0               0.0           0.0   \n",
            "3044           30.5  ...                  0.0               0.0           0.0   \n",
            "3045           36.9  ...                  0.0               0.0           0.0   \n",
            "3046           25.5  ...                  0.0               0.0           0.0   \n",
            "\n",
            "      state_ Utah  state_ Vermont  state_ Virginia  state_ Washington  \\\n",
            "0             0.0             0.0              0.0                1.0   \n",
            "1             0.0             0.0              0.0                1.0   \n",
            "2             0.0             0.0              0.0                1.0   \n",
            "3             0.0             0.0              0.0                1.0   \n",
            "4             0.0             0.0              0.0                1.0   \n",
            "...           ...             ...              ...                ...   \n",
            "3042          0.0             0.0              0.0                0.0   \n",
            "3043          0.0             0.0              0.0                0.0   \n",
            "3044          0.0             0.0              0.0                0.0   \n",
            "3045          0.0             0.0              0.0                0.0   \n",
            "3046          0.0             0.0              0.0                0.0   \n",
            "\n",
            "      state_ West Virginia  state_ Wisconsin  state_ Wyoming  \n",
            "0                      0.0               0.0             0.0  \n",
            "1                      0.0               0.0             0.0  \n",
            "2                      0.0               0.0             0.0  \n",
            "3                      0.0               0.0             0.0  \n",
            "4                      0.0               0.0             0.0  \n",
            "...                    ...               ...             ...  \n",
            "3042                   0.0               0.0             0.0  \n",
            "3043                   0.0               0.0             0.0  \n",
            "3044                   0.0               0.0             0.0  \n",
            "3045                   0.0               0.0             0.0  \n",
            "3046                   0.0               0.0             0.0  \n",
            "\n",
            "[3047 rows x 1904 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgwOuo1N55ET",
        "outputId": "b2672f07-c6c0-408d-e688-3bfbe5dc859a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3047, 1904)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"data_processed.csv\", index=False)"
      ],
      "metadata": {
        "id": "giIWHuyWBMqk"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DkVP-HHtBku5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}